{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diwwae/MatModSchool/blob/main/%D0%9C%D0%B0%D1%82_%D0%BC%D0%BE%D0%B4_%D0%A3%D1%87%D0%B5%D0%B1%D0%BD%D1%8B%D0%B9_%D0%BA%D0%B5%D0%B9%D1%81_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6vtSsfypQ1A"
      },
      "source": [
        "### О кейсе\n",
        "\n",
        "Кейс состоит из последовательных вопросов\n",
        "\n",
        "(отвечать на них обязательно, код и графики без интерпретации не имеют никакого смысла, **иначе - снижение баллов**), посвященных работе с табличными данными, но на более низком уровне с помощью Numpy\n",
        "\n",
        "Баллы даются за выполнение отдельных пунктов\n",
        "\n",
        "(Максимальное количество баллов за этот кейс - 10 (чтобы вам было проще оценивать свои успехи))\n",
        "\n",
        "Задачи в рамках одного раздела рекомендуется решать в том порядке, в котором они даны в задании.\n",
        "\n",
        "В этом задании мы попытаемся научиться анализировать данные и выделять из них полезные признаки. Мы также научимся пользоваться `seaborn` и `sklearn`, а заодно привыкнем к основным понятиям машинного обучения.\n",
        "\n",
        "Неэффективная реализация кода может негативно отразиться на оценке.\n",
        "Также оценка может быть снижена за плохо читаемый код и плохо считываемые диаграммы.\n",
        "\n",
        "Если эксперт заметит плагиат - баллы за ваше решения также снижаются.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Кейс"
      ],
      "metadata": {
        "id": "SNk1npyYt0Ag"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLpCvqdMpQ1B"
      },
      "source": [
        "## Часть 0. Подготовка [+0.5 балла]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg2TuAAlpQ1B"
      },
      "source": [
        "**Задание 1 [+0.5 балла]**. Мы будем работать с данными из соревнования [New York City Taxi Trip Duration](https://www.kaggle.com/c/nyc-taxi-trip-duration/overview), в котором нужно было предсказать длительность поездки на такси. Скачайте обучающую выборку из этого соревнования и загрузите ее:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-26T17:03:41.260445Z",
          "start_time": "2020-09-26T17:03:37.878813Z"
        },
        "id": "HufLP60UpQ1C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "818cd155-1e7d-4962-f0e5-a560db416806"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e8d4626f32fb>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
          ]
        }
      ],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"train.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhQvmDwHpQ1C"
      },
      "source": [
        "В колонке `dropoff_datetime` содержится информация о времени окончания поездки, однако эта колонка присутствует только в обучающей выборке и отсутствует в тестовой. Это создаёт проблему, так как при обучении модели мы не сможем использовать эту колонку для предсказаний на новых данных. В связи с этим, чтобы избежать ошибок и упростить анализ, рекомендуется удалить колонку `dropoff_datetime` из датасета.\n",
        "\n",
        "Колонка `pickup_datetime` содержит дату и время начала поездки в формате строки, что затрудняет выполнение операций с датами и временем, таких как вычисление продолжительности поездки или анализ зависимости цены от времени суток. Преобразование этих данных в `datetime`-объекты позволит использовать методы для работы с датой (вместо огромного количества строк для решения какой-нибудь маленькой подзадачи будет использоваться один вызов метода)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUL1GVVnpQ1C"
      },
      "outputs": [],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ivHK51upQ1C"
      },
      "source": [
        "В колонке `trip_duration` содержится значение, которое мы стремимся предсказать. Давайте изучим распределение целевой переменной в обучающем наборе данных. Для этого построим гистограмму этой переменной.\n",
        "\n",
        "Построение гистограммы целевой переменной важно по нескольким причинам:\n",
        "\n",
        "1. **Понимание распределения**: Гистограмма помогает нам увидеть, как распределены значения целевой переменной. Это может дать представление о том, является ли распределение нормальным, скошенным или имеет выбросы.\n",
        "\n",
        "2. **Выявление аномалий**: При анализе гистограммы мы можем обнаружить аномальные значения или выбросы, которые могут повлиять на качество модели.\n",
        "\n",
        "3. **Выбор подходящего алгоритма**: Понимание распределения целевой переменной может помочь в выборе наиболее правильного анализа датасета. Например, если данные сильно скошены, может потребоваться преобразование данных перед обучением модели. (как на практическом занятии, если у нас таргет расположен по экспоненте, то было бы классно предсказывать логарифм, а не экспоненту (подробнее было на лекции))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSGYlRz1pQ1C"
      },
      "outputs": [],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-eMF2_lpQ1C"
      },
      "source": [
        "**Вопрос**: Что можно сказать о целевой переменной по гистограмме её значений?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ],
      "metadata": {
        "id": "5R3oBIU8v7gS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NV_IF2QGv4R8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFw0Ukp_pQ1C"
      },
      "source": [
        "В соревновании в качестве метрики качества использовалось RMSLE:\n",
        "$$\\text{RMSLE}(X, y, a) = \\sqrt{\\frac{1}{\\ell}\\sum_{i=1}^{\\ell} \\big(\\log{(y_i + 1)} - \\log{(a(x_i) + 1)}\\big)^2}$$\n",
        "\n",
        "**Вопрос**: Как вы думаете, почему авторы соревнования выбрали именно RMSLE, а не RMSE?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ],
      "metadata": {
        "id": "UCmwhidyv_Vv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXy-sovapQ1C"
      },
      "source": [
        "Мы изучили несколько вариантов линейной регрессии в sklearn, но все они минимизировали среднеквадратичную ошибку (MSE), а не среднеквадратичную логарифмическую ошибку (RMSLE). Для работы с RMSLE мы можем использовать следующий подход: вместо прямого предсказания целевой переменной, мы будем предсказывать ее логарифм. Пусть $\\hat{y}_i = \\log{(y_i + 1)}$ будет модифицированной целевой переменной, а $\\hat{a}(x_i)$ — предсказание модели, обученной на $\\hat{y}_i$. Чтобы получить исходное предсказание, мы используем обратное преобразование: $a(x_i) = \\exp(\\hat{a}(x_i)) - 1$.\n",
        "\n",
        "\\\n",
        "\n",
        "Это преобразование позволяет нам оптимизировать MSE для логарифмированных значений, что эквивалентно оптимизации RMSLE для исходных значений. Это связано с тем, что минимизация квадратичной ошибки между логарифмами прогнозов и реальных значений соответствует минимизации логарифмической ошибки между самими прогнозами и реальными значениями ***(для дополнительного балла можете доказать почему)***. Таким образом, этот подход позволяет использовать стандартные методы линейной регрессии для задач, где требуется минимизировать RMSLE.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjpGjs3opQ1D"
      },
      "outputs": [],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcCsbYgcpQ1D"
      },
      "source": [
        "Чтобы иметь некоторую точку отсчета, давайте посчитаем значение метрики при наилучшем константном предсказании:\n",
        "\n",
        "***(Какая константа прекрасно оптимизирует RMSLE MSE (с преобразованиями?))***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yi0glg_CpQ1D"
      },
      "outputs": [],
      "source": [
        "def rmsle(log1p_y_true, log1p_y_pred):\n",
        "    #╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ\n",
        "    pass\n",
        "\n",
        "rmsle_best_const = ... # как вычислить ее?\n",
        "print(rmsle_best_const)\n",
        "assert np.allclose(rmsle_best_const, 0.79575, 1e-4) # ответ конечно же нельзя подсматривать"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUJVtE6OpQ1D"
      },
      "source": [
        "## Часть 1. Изучаем `pickup_datetime` & Обучаем модель [+1 балл]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 2 [+0.125 балла]**. Для начала давайте проанализируем общее количество поездок по дням. Построим график, отражающий зависимость числа поездок от конкретного дня в году (например, можно использовать `sns.countplot`).\n",
        "\n",
        "Просмотр этой информации важен по нескольким причинам:\n",
        "\n",
        "1. **Выявление закономерностей**: Анализ количества поездок по дням может помочь выявить определенные закономерности или тренды, например, повышенный спрос в выходные дни или праздничные периоды.\n",
        "\n",
        "2. **Обнаружение аномалий**: График может помочь идентифицировать дни с необычно высоким или низким количеством поездок, что может указывать на наличие аномалий или особых событий.\n",
        "\n",
        "3. **Корректировка моделей**: Если анализ показывает, что спрос сильно колеблется в зависимости от дня, это может потребовать учета этого фактора в моделях прогнозирования."
      ],
      "metadata": {
        "id": "gqQcg3WUE_cy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3m1SDF_pQ1D"
      },
      "outputs": [],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABPXP0bnpQ1E"
      },
      "source": [
        "**Вопрос**: Вы, вероятно, заметили, что на графике есть 2 периода с аномально маленькими количествами поездок. Вычислите, в какие даты происходили эти скачки вниз и найдите информацию о том, что происходило в эти дни в Нью-Йорке.\n",
        "\n",
        "Нарисуйте графики зависимости количества поездок от дня недели и от часов в сутках (воспользуйтесь `sns.relplot`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Km02wMAfpQ1E"
      },
      "outputs": [],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONhZwfBtpQ1E"
      },
      "source": [
        "**Задание 3 [+0.25 балла]**. Постройте график, на котором будет отображена зависимость числа поездок от времени суток для различных месяцев. Используйте разные цвета для кривых, соответствующих разным месяцам, с помощью параметра `hue` в `sns.relplot`. Аналогичным образом постройте график, показывающий зависимость количества поездок от часа в сутках для разных дней недели.\n",
        "\n",
        "Это важно по нескольким причинам:\n",
        "\n",
        "1. **Выявление временных закономерностей**: Графики помогут увидеть, как спрос на поездки меняется в течение суток в разные месяцы и дни недели. Это может выявить определенные тренды, например, пиковые часы поездок или временные периоды с низким спросом.\n",
        "\n",
        "2. **Адаптация к сезонности и недельным циклам**: Понимание того, как спрос на поездки меняется в зависимости от времени года и дня недели, позволяет адаптировать модель машинного обучения и сделать правильный feature-engineering (правильную предобработку данных)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17xITNLYpQ1E"
      },
      "outputs": [],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вопрос**: Какие выводы можно сделать, основываясь на графиках выше? Выделяются ли какие-нибудь дни недели? Месяца? Время суток? С чем это может быть связано?"
      ],
      "metadata": {
        "id": "JdPTN-LXzx8k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ],
      "metadata": {
        "id": "izIzJFMzz3wG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4ZNw_kUpQ1E"
      },
      "source": [
        "**Задание 4 [+0.25 балла]**. Разделите данные на обучающую и тестовую выборки в соотношении 80:20 с помощью функции `train_test_split` из библиотеки `sklearn`. На основе обучающей выборки постройте график, показывающий зависимость логарифма среднего времени поездки от дня недели. Повторите этот процесс для часа в сутках и дня в году.\n",
        "\n",
        "Посмотреть график распределения тренировочной выборки важно по нескольким причинам:\n",
        "\n",
        "1. **Понимание данных**: Анализ тренировочной выборки помогает лучше понять распределение и характеристики данных, что важно для выбора и настройки моделей машинного обучения\n",
        "\n",
        "2. **Выявление закономерностей**: Графики зависимостей могут выявить важные закономерности и тренды в данных, которые могут быть использованы для улучшения моделей прогнозирования.\n",
        "\n",
        "3. **Избежание переобучения**: Анализируя только тренировочную выборку, мы избегаем риска \"заглядывания в будущее\" и переобучения модели, когда она слишком хорошо подгоняется под тестовые данные.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaFVHnU8pQ1E"
      },
      "outputs": [],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ],
      "metadata": {
        "id": "FcxUEqc81j0s"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO04R6DtpQ1F"
      },
      "source": [
        "Добавьте следующие признаки на основе `pickup_datetime` (не зря мы преобразовывали это в первых этапах):\n",
        "1. День недели\n",
        "2. Месяц\n",
        "3. Час\n",
        "4. Является ли период аномальным (два бинарных признака, соответствующие двум аномальным периодам)\n",
        "5. Номер дня в году\n",
        "\n",
        "Разбиение даты на отдельные признаки важно по нескольким причинам:\n",
        "\n",
        "1. **Выявление временных закономерностей**: Разделение даты на день недели, месяц и час помогает выявить закономерности в данных, связанные с временем суток, днями недели и сезонностью.\n",
        "\n",
        "2. **Улучшение прогностической способности модели**: Добавление этих признаков может улучшить точность моделей машинного обучения, поскольку они могут захватывать важные временные зависимости в данных.\n",
        "\n",
        "3. **Адаптация к аномальным событиям**: Бинарные признаки, указывающие на аномальные периоды, позволяют модели учитывать особые ситуации, которые могут существенно отличаться от обычных условий.\n",
        "\n",
        "4. **Повышение интерпретируемости**: Разбиение даты на отдельные компоненты делает модель более интерпретируемой, позволяя легче понять, как различные временные факторы влияют на целевую переменную."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXHIJPwfpQ1F"
      },
      "outputs": [],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZYuMNlLpQ1F"
      },
      "source": [
        "Итак, мы уже создали некоторое количество признаков.\n",
        "\n",
        "**Вопрос**: Какие из признаков _стоит рассматривать в этой задаче_   как категориальные, а какие - как численные? Почему?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1o-42dCwpQ1F"
      },
      "source": [
        "**Задание 5 [+0.375 балла]**.\n",
        "Обучите регрессию `Ridge` с использованием параметров по умолчанию, применив `OneHotEncoder` для кодирования всех категориальных признаков и `StandardScaler` для масштабирования численных признаков (используйте `ColumnTransformer` и `PipeLine`. Ограничьтесь признаками, которые мы определили в этой части задания. Замерьте качество на тестовой выборке (RMSLE)\n",
        "\n",
        "Применение `OneHotEncoder` и `StandardScaler` важно по следующим причинам:\n",
        "\n",
        "1. **OneHotEncoder для категориальных признаков**: Категориальные признаки необходимо преобразовать в числовой формат перед использованием в линейной регрессии. `OneHotEncoder` преобразует категориальные переменные в бинарные векторы, что позволяет модели корректно интерпретировать эти признаки без внесения искажений, связанных с порядком значений.\n",
        "\n",
        "2. **StandardScaler для численных признаков**: Масштабирование численных признаков с помощью `StandardScaler` помогает стандартизировать данные, приводя их к одному масштабу с нулевым средним и единичным стандартным отклонением. Это улучшает интерпретацию весов линейной модели (а также мы обсудим на лекции, почему это ускоряет обучение модели)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PLf7fI5pQ1F"
      },
      "outputs": [],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLcAEIdspQ1F"
      },
      "source": [
        "## Часть 2. Изучаем координаты & Обучаем модель [+1.5 балла]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь, когда мы подробно изучили временные аспекты данных о поездках, давайте переключим наше внимание на географические данные, а именно на координаты начала и конца поездок. Мы предоставили вам функцию, которая отображает на карте точки начала или конца поездок. Однако обратите внимание, что для эффективности этой функции мы используем только небольшой фрагмент данных, иначе обработка займет слишком много времени.\n",
        "\n",
        "Анализ координат важен по нескольким причинам:\n",
        "\n",
        "1. **Пространственный анализ**: Координаты позволяют проводить пространственный анализ, который может выявить географические закономерности в данных, такие как популярные места отправления и назначения, районы с высоким спросом и т. д.\n",
        "\n",
        "2. **Улучшение точности прогнозов**: Включение географических признаков в модели прогнозирования может повысить их точность, поскольку координаты могут быть связаны с различными факторами, влияющими на длительность поездок и спрос на транспортные услуги."
      ],
      "metadata": {
        "id": "XVVjpUo0E1l7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_YLiJy1pQ1F"
      },
      "outputs": [],
      "source": [
        "def show_circles_on_map(data, latitude_column, longitude_column, color):\n",
        "    \"\"\"\n",
        "    Рисует карту с кругами, представляющими точки данных.\n",
        "\n",
        "    Параметры\n",
        "    ----------\n",
        "    data : DataFrame\n",
        "        DataFrame, содержащий колонки с широтой и долготой.\n",
        "    latitude_column : str\n",
        "        Название колонки в DataFrame, содержащей координаты широты.\n",
        "    longitude_column : str\n",
        "        Название колонки в DataFrame, содержащей координаты долготы.\n",
        "    color : str\n",
        "        Цвет кругов, которые будут нарисованы на карте.\n",
        "\n",
        "    Возвращает\n",
        "    -------\n",
        "    folium.Map\n",
        "        Объект карты Folium с нарисованными кругами в указанных координатах.\n",
        "\n",
        "    Примеры\n",
        "    --------\n",
        "    >>> import pandas as pd\n",
        "    >>> data = pd.DataFrame({\n",
        "    ...     'latitude': [37.773972, 37.774159],\n",
        "    ...     'longitude': [-122.431297, -122.431297]\n",
        "    ... })\n",
        "    >>> show_circles_on_map(data, 'latitude', 'longitude', 'blue')\n",
        "    \"\"\"\n",
        "\n",
        "    location = (data[latitude_column].mean(), data[longitude_column].mean())\n",
        "    m = folium.Map(location=location)\n",
        "\n",
        "    for _, row in data.iterrows():\n",
        "        folium.Circle(\n",
        "            radius=100,\n",
        "            location=(row[latitude_column], row[longitude_column]),\n",
        "            color=color,\n",
        "            fill_color=color,\n",
        "            fill=True\n",
        "        ).add_to(m)\n",
        "\n",
        "    return m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-26T17:05:15.969248Z",
          "start_time": "2020-09-26T17:05:15.334200Z"
        },
        "id": "5vZorMsepQ1F"
      },
      "outputs": [],
      "source": [
        "show_circles_on_map(df.sample(1000), \"pickup_latitude\", \"pickup_longitude\", \"blue\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-26T17:05:16.699973Z",
          "start_time": "2020-09-26T17:05:16.026291Z"
        },
        "id": "8AlmNUnkpQ1G"
      },
      "outputs": [],
      "source": [
        "show_circles_on_map(df.sample(1000), \"dropoff_latitude\", \"dropoff_longitude\", \"blue\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oclihdlepQ1G"
      },
      "source": [
        "**Вопрос**: Какие пункты (или скопления точек, в количестве 2-3), по вашему мнению, выделяются на карте от основной массы и могут быть полезны для нашей задачи? Почему вы их выбрали? В чём особенность этих скоплений точек для нашей задачи?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ],
      "metadata": {
        "id": "ZnYLjJDt3ykQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOsQzd_4pQ1G"
      },
      "source": [
        "**Задание 6 [+0.375 балла]**. Как нам хорошо известно, время поездки $t$ связано с расстоянием $s$ и средней скоростью $v_{\\text{ср}}$ соотношением $t = s / v_{\\text{ср}}$. Из этого следует, что расстояние между начальной и конечной точками поездки является одним из ключевых факторов, влияющих на время поездки. Хотя мы не можем точно определить полный маршрут, который преодолеет такси, мы можем оценить это расстояние, рассчитав кратчайшее расстояние между точками начала и конца поездки. Для корректного вычисления расстояния между двумя точками на поверхности Земли можно использовать функцию `haversine`. Рассчитайте кратчайшее расстояние для каждого объекта в данных и сохраните его в колонку `haversine`.\n",
        "\n",
        "Это важно по нескольким причинам:\n",
        "\n",
        "1. **Улучшение точности модели**: Включение расстояния как признака в модель может значительно улучшить точность прогнозирования времени поездки, поскольку оно напрямую влияет на длительность поездки.\n",
        "\n",
        "2. **Понимание взаимосвязей**: Анализ зависимости времени поездки от расстояния может помочь выявить взаимосвязи и закономерности в данных, что полезно для понимания динамики транспортных потоков.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLBuqROWpQ1G"
      },
      "outputs": [],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJ0lHOGapQ1G"
      },
      "source": [
        "Так как мы предсказываем логарифм времени поездки и хотим, чтобы наши признаки были линейно зависимы с этой целевой переменной, нам нужно логарифмировать расстояние: $\\log t = \\log s - \\log{v_{\\text{ср}}}$. Запишите логарифм `haversine` в отдельную колонку `log_haversine`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZUsXrQypQ1G"
      },
      "outputs": [],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0u6P0TzpQ1G"
      },
      "source": [
        "Убедимся, что логарифм расстояния лучше коррелирует с нашим таргетом, чем просто расстояние:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpbf5ZvTpQ1G"
      },
      "outputs": [],
      "source": [
        "your_df = ...\n",
        "assert your_df['log_haversine'].corr(your_df['log_trip_duration']) > your_df['haversine'].corr(your_df['log_trip_duration'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFwvXg-dpQ1G"
      },
      "source": [
        "**Задание 7 [+0.375 балла]**. Давайте проанализируем среднюю скорость движения такси. Для каждого объекта в обучающей выборке вычислите среднюю скорость, разделив значение в колонке `haversine` на значение в колонке `trip_duration`. Затем постройте гистограмму распределения полученных значений средней скорости.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTuN-4fRpQ1H"
      },
      "outputs": [],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHOC3298pQ1H"
      },
      "source": [
        "Как можно видеть по гистограмме, для некоторых объектов у нас получились очень больше значения скоростей. Нарисуйте гистограмму по объектам, для которых значение скорости получилось разумным (например, можно не включать рассмотрение объекты, где скорость больше некоторой квантили):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eliikfRWpQ1H"
      },
      "outputs": [],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yt4xsa4pQ1H"
      },
      "source": [
        "Не забудьте удалить колонку со значением скорости из данных!\n",
        "\n",
        "**Вопрос**: Почему значение скорости нельзя использовать во время обучения?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ],
      "metadata": {
        "id": "Wo5AO4ZI5mt1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZsVupVMpQ1H"
      },
      "source": [
        "<img src=\"https://www.dropbox.com/s/xson9nukz5hba7c/map.png?raw=1\" align=\"right\" width=\"20%\" style=\"margin-left: 20px; margin-bottom: 20px\">\n",
        "\n",
        "**Задание 8 [+0.625 балла]**. Сейчас мы практически не используем прямые значения координат в анализе. Это связано с тем, что широта и долгота по отдельности не несут значимой информации, а их взаимосвязь с целевой переменной нелинейна. Чтобы эффективно интегрировать координаты в наш анализ, мы можем применить следующий подход: окружим область с наибольшим количеством поездок прямоугольником и разделим этот прямоугольник на ячейки. Каждой точке присвоим номер ячейки, в которой она находится, а точкам вне прямоугольника присвоим значение -1.\n",
        "\n",
        "Создайте трансформер, который вначале делит указанную область на ячейки, а затем генерирует два признака: номер ячейки начала поездки и номер ячейки конца поездки. Выбор количества строк и столбцов оставьте на ваше усмотрение.\n",
        "\n",
        "Важно, чтобы все вычисления были векторизованными, трансформер не изменял исходный набор данных, а все необходимые статистики вычислялись только по обучающей выборке в методе `fit`.\n",
        "\n",
        "Этот подход важен по следующим причинам:\n",
        "\n",
        "1. **Учет пространственной структуры**: Разбиение на ячейки позволяет учесть пространственную структуру данных, что может улучшить качество анализа и прогнозирования.\n",
        "\n",
        "2. **Снижение размерности**: Преобразование координат в номера ячеек уменьшает размерность данных, что упрощает анализ и сокращает время вычислений.\n",
        "\n",
        "3. **Улучшение интерпретируемости**: Номера ячеек могут быть более интерпретируемыми, чем сырые координаты, что облегчает понимание взаимосвязей в данных.\n",
        "\n",
        "4. **Адаптация к нелинейным зависимостям**: Такой подход позволяет адаптироваться к нелинейным зависимостям между координатами и целевой переменной, что может повысить точность моделей."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkV42yvhpQ1H"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class MapGridTransformer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Трансформер для преобразования географических координат в номера ячеек сетки.\n",
        "\n",
        "    Параметры\n",
        "    ----------\n",
        "    n_rows : int\n",
        "        Количество строк сетки.\n",
        "    n_cols : int\n",
        "        Количество столбцов сетки.\n",
        "    lat_min : float\n",
        "        Минимальная широта области.\n",
        "    lat_max : float\n",
        "        Максимальная широта области.\n",
        "    lon_min : float\n",
        "        Минимальная долгота области.\n",
        "    lon_max : float\n",
        "        Максимальная долгота области.\n",
        "\n",
        "    Атрибуты\n",
        "    ----------\n",
        "    cell_size_lat : float\n",
        "        Размер ячейки сетки по широте.\n",
        "    cell_size_lon : float\n",
        "        Размер ячейки сетки по долготе.\n",
        "\n",
        "    Методы\n",
        "    -------\n",
        "    fit(X, y=None)\n",
        "        Находит параметры сетки на основе данных.\n",
        "    transform(X)\n",
        "        Преобразует координаты в номера ячеек сетки.\n",
        "    show_map()\n",
        "        Отображает карту с ячейками сетки.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_rows, n_cols, lat_min, lat_max, lon_min, lon_max):\n",
        "        #╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ\n",
        "\n",
        "    def fit(self, X=None, y=None):\n",
        "        \"\"\"\n",
        "        Находит параметры сетки на основе данных.\n",
        "\n",
        "        Параметры\n",
        "        ----------\n",
        "        X : array-like, shape [n_samples, 2]\n",
        "            Входные данные с координатами (широта, долгота).\n",
        "        y : Ignored\n",
        "            Не используется, существует для совместимости со стандартами sklearn.\n",
        "\n",
        "        Возвращает\n",
        "        -------\n",
        "        self : object\n",
        "            Возвращает себя.\n",
        "        \"\"\"\n",
        "        #╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Преобразует координаты в номера ячеек сетки.\n",
        "\n",
        "        Параметры\n",
        "        ----------\n",
        "        X : array-like, shape [n_samples, 2]\n",
        "            Входные данные с координатами (широта, долгота).\n",
        "\n",
        "        Возвращает\n",
        "        -------\n",
        "        X_transformed : array, shape [n_samples, 2]\n",
        "            Преобразованные данные с номерами ячеек (номер строки, номер столбца).\n",
        "        \"\"\"\n",
        "        #╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ\n",
        "        return X_transformed\n",
        "\n",
        "    def show_map(self):\n",
        "        \"\"\"\n",
        "        Отображает карту с ячейками сетки.\n",
        "        \"\"\"\n",
        "        #╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aCNwYH6pQ1I"
      },
      "source": [
        "**Задание 9 [+0.125 балла]**. Обучите регрессию `Ridge` с использованием параметров по умолчанию, применив `OneHotEncoder` для кодирования всех категориальных признаков и `StandardScaler` для масштабирования численных признаков (используйте `ColumnTransformer` и `PipeLine`. Ограничьтесь признаками, которые мы определили до этой части задания. Замерьте качество на тестовой выборке (RMSLE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxj9PQQbpQ1I"
      },
      "outputs": [],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOshi7fHpQ1I"
      },
      "source": [
        "## Часть 3. Изучаем оставшиеся признаки & Обучаем модель [+0.5 балла]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 10 [+0.375 балла]**. У нас осталось еще 3 признака, которые мы не исследовали: `vendor_id`, `passenger_count` и `store_and_fwd_flag`.\n",
        "\n",
        "**Вопрос**: Подумайте, почему каждый из этих признаков может быть потенциально полезным.\n",
        "\n",
        "Посчитайте, сколько есть уникальных значений у каждого из этих признаков:"
      ],
      "metadata": {
        "id": "Yq-AX2nJD-2f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7y_VsLUpQ1I"
      },
      "outputs": [],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ],
      "metadata": {
        "id": "Iw6zbOOyD3Er"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyfUfA_4pQ1I"
      },
      "source": [
        "Постройте \"ящики с усами\" распределений логарифма времени поездки в зависимости от значений каждого из признаков"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOevcAt9pQ1I"
      },
      "outputs": [],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g4LaVkKpQ1I"
      },
      "source": [
        "Переведите признаки `vendor_id` и `store_and_fwd_flag` в значения $\\{0;1\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GI52xAKQpQ1I"
      },
      "outputs": [],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ3osFdApQ1I"
      },
      "source": [
        "**Вопрос**: Основываясь на графиках выше, как вы думаете, будут ли эти признаки сильными?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpxeHe9ypQ1I"
      },
      "source": [
        "**Задание 11 [+0.125 балла]**. Обучите регрессию `Ridge` с использованием параметров по умолчанию, применив `OneHotEncoder` для кодирования всех категориальных признаков и `StandardScaler` для масштабирования численных признаков (используйте `ColumnTransformer` и `PipeLine`. Ограничьтесь признаками, которые мы определили в этой части задания. Замерьте качество на тестовой выборке (RMSLE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLEGLN43pQ1I"
      },
      "outputs": [],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3kbdL5opQ1I"
      },
      "source": [
        "Если признаки не дали какого-то ощутимого улучшения метрики, их можно выбросить из данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgCQAoNapQ1I"
      },
      "source": [
        "## Часть 4. Улучшаем модель [+1.5 балла]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdpLMyYepQ1I"
      },
      "source": [
        "**Задание 12 [+0.5 балла]**. В нашем наборе данных присутствуют аномальные записи: объекты с необычно коротким временем поездки, слишком большим пройденным расстоянием или с большими остатками после регрессии. В этом задании предлагается исключить такие объекты из обучающего набора. Для этого постройте гистограммы распределения указанных величин, определите объекты, которые можно считать выбросами, и очистите __обучающий набор__ от них.\n",
        "\n",
        "Следует отметить, что, несмотря на то что эти объекты кажутся выбросами, в тестовом наборе данных также могут присутствовать объекты с аналогичными аномальными значениями. Поэтому удаление выбросов из обучающего набора может привести к ухудшению качества на тестовом наборе. Однако, в целом, рекомендуется удалять выбросы из обучающего набора, чтобы получить более разумную и интерпретируемую модель.\n",
        "\n",
        "Для определения выбросов можно использовать различные методы, такие как:\n",
        "\n",
        "- **Z-оценка**: Выбросы определяются как объекты, у которых абсолютное значение Z-оценки (стандартизированное значение) превышает определенный порог (например, 3).\n",
        "\n",
        "- **IQR (межквартильный размах)**: Выбросы определяются как объекты, значения которых выходят за пределы [Q1 - 1.5 * IQR, Q3 + 1.5 * IQR], где Q1 и Q3 — первый и третий квартили соответственно.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1kKlWE3pQ1I"
      },
      "outputs": [],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0L_dB_CpQ1J"
      },
      "source": [
        "Сейчас у нас очень много категориальных признаков. В категориальных признаках могут содержаться редкие категории, обычно это плохо: модель сильно переобучается на таких примерах. Для каждого категориального признака объедините действительно редкие категории в одну, если такие имеются (т.е. если категории действительно редкие)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGmHMxUXpQ1J"
      },
      "outputs": [],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Off_qx1rpQ1J"
      },
      "source": [
        "Обучите регрессию `Ridge` с использованием параметров по умолчанию, применив `OneHotEncoder` для кодирования всех категориальных признаков и `StandardScaler` для масштабирования численных признаков (используйте `ColumnTransformer` и `PipeLine`. Ограничьтесь признаками, которые мы сделали до этой части задания. Замерьте качество на тестовой выборке (RMSLE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ],
      "metadata": {
        "id": "WVuLa0jSCYJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVqtodcIpQ1J"
      },
      "source": [
        "**Задание 13 [+0.5 балла]**. После OneHot-кодирования количество признаков в нашем датасете сильно возрастает. Посчитайте колиество признаков до и после кодирования категориальных признаков."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgonugaSpQ1J"
      },
      "outputs": [],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF8cy5GdpQ1J"
      },
      "source": [
        "Попробуйте обучить не `Ridge`-, а `Lasso`-регрессию. Какой метод лучше?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aIOPiQrpQ1J"
      },
      "outputs": [],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KXqwsp6pQ1J"
      },
      "source": [
        "По тренировочной выборке с помощью кросс-валидации (`zGridSearchCV`) подберите оптимальные значения параметра регуляризации (alpha, lambda в разных литературах по-разному) для `Ridge` и `Lasso` на тестовой выборке измерьте качество лучшей полученной модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSQDIKPlpQ1J"
      },
      "outputs": [],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quN3VUl2pQ1J"
      },
      "source": [
        "<img src=\"https://www.dropbox.com/s/wp4jj0599np17lh/map_direction.png?raw=1\" width=\"20%\" align=\"right\" style=\"margin-left: 20px\">\n",
        "\n",
        "**Задание 14 [+0.5 балла]**. Использование взаимодействия признаков часто оказывается полезным для улучшения качества модели. Мы уже разделили карту Манхэттена на ячейки и создали признаки, указывающие на ячейку начала и окончания поездки.\n",
        "\n",
        "Теперь предлагается пойти дальше и посчитать, как часто встречается каждая возможная пара этих признаков в нашем наборе данных. Затем выберем 100 самых частых пар и закодируем поездки с этими парами как категориальный признак, а для остальных объектов установим значение -1. Таким образом, мы сможем кодировать информацию о маршруте поездки такси.\n",
        "\n",
        "Создание таких признаков может быть круто по нескольким причинам:\n",
        "\n",
        "1. **Улучшение предсказаний**: Комбинация начальной и конечной точек поездки может содержать важную информацию о времени поездки, которая поможет улучшить предсказательную способность модели.\n",
        "\n",
        "2. **Выявление популярных маршрутов**: Анализ самых частых пар ячеек может помочь выявить наиболее популярные маршруты, что может быть полезно для планирования транспортных услуг.\n",
        "\n",
        "3. **Интерпретируемость**: Новые признаки, основанные на маршрутах, могут улучшить интерпретируемость модели, позволяя лучше понять, как различные маршруты влияют на время поездки.\n",
        "\n",
        "4. **Адаптация к специфике данных**: Такой подход позволяет адаптировать модель к специфике данных о поездках такси, учитывая географическую структуру города и особенности движения.\n",
        "\n",
        "Также вы можете придумать другие способы создания признаков, связанных с маршрутом, которые могут дать дополнительные баллы при сдаче этого домашнего задания\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ryt11UbNpQ1J"
      },
      "outputs": [],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вопрос**: Почему такой признак потенциально полезный? Почему линейная модель не может самостоятельно \"вытащить\" эту информацию, ведь у нее в распоряжении есть признаки \"из какой ячейки началась поездка\" и \"в какой ячейке закончилась поездка\"?"
      ],
      "metadata": {
        "id": "3zp4g6xfDkky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ],
      "metadata": {
        "id": "nEmk0H30Dli6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp2O4C_JpQ1J"
      },
      "source": [
        "Заново обучите модель (`Ridge`, если она дала более высокое качество в предыдущих экспериментах, и `Lasso` иначе) на новых даннных и посчитайте качество на тестовой выборке"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXGoIiFnpQ1J"
      },
      "outputs": [],
      "source": [
        "#╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Часть 5. САМОЕ ВАЖНОЕ [+5 баллов]\n",
        "\n",
        "Время соревнований. Кто сделает лучшую метрику RMSLE - тот победил. Разрешено использовать любые модели\n",
        "\n",
        "RMSLE < 0.28 - 5 баллов\n",
        "\n",
        "0.315 > RMSLE >= 0.28 - 4 балла\n",
        "\n",
        "0.34 > RMSLE >= 0.315 - 3 балла\n",
        "\n",
        "0.36 > RMSLE >= 0.34 - 2 балла\n",
        "\n",
        "RMSLE > 0.36 - 0 баллов"
      ],
      "metadata": {
        "id": "zQTDKs7i8jBr"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}